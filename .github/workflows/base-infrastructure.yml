name: Base Infrastructure Pipeline

# This pipeline manages the complete infrastructure deployment with proper dependency ordering:
# 1. Terraform State Backend Bootstrap (creates S3 + DynamoDB for state management)
# 2. Infrastructure Deployment (Hetzner k3s, Cloudflare, etc.)
# 3. Validation & Testing
# 4. Security Scanning

on:
  push:
    branches: [main]
    paths:
      - "infra/**"
      - "k8s/**"
      - ".github/workflows/base-infrastructure.yml"
  pull_request:
    branches: [main]
    paths:
      - "infra/**"
      - "k8s/**"
      - ".github/workflows/base-infrastructure.yml"
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy infrastructure to"
        required: true
        default: "dev"
        type: choice
        options:
          - dev
          # - qa  # Commented out - QA deployments disabled
          # - uat # Commented out - UAT deployments disabled
          - prod
      action:
        description: "Action to perform"
        required: true
        default: "plan"
        type: choice
        options:
          - plan
          - apply
          - destroy

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  TF_VERSION: "1.8.0"
  INFRA_REGION: ap-southeast-1

jobs:
  # ===== TERRAFORM STATE BACKEND BOOTSTRAP =====
  bootstrap:
    name: "Terraform State Backend Bootstrap"
    runs-on: ubicloud-standard-2-arm
    permissions:
      id-token: write
      contents: write
    env:
      TF_WORKING_DIR: infra/pipeline
    if: github.event_name != 'workflow_dispatch' || github.event.inputs.action != 'plan'
    outputs:
      state_bucket: ${{ steps.bootstrap.outputs.state_bucket }}
      dynamodb_table: ${{ steps.bootstrap.outputs.dynamodb_table }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate Variables
        run: |
          if [ -z "${{ vars.MANAGEMENT_ACCOUNT_ID }}" ]; then
            echo "‚ùå Error: MANAGEMENT_ACCOUNT_ID variable is not set"
            exit 1
          fi
          echo "‚úÖ MANAGEMENT_ACCOUNT_ID configured"

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ vars.MANAGEMENT_ACCOUNT_ID }}:role/${{ vars.AWS_PIPELINE_ROLE }}
          aws-region: ${{ env.INFRA_REGION }}

      - name: Bootstrap Terraform State Backend
        id: bootstrap
        run: |
          cd ${{ env.TF_WORKING_DIR }}/bootstrap
          echo "üöÄ Bootstrapping Terraform state backend..."

          STATE_BUCKET="magebase-tf-state-management-ap-southeast-1"
          DYNAMODB_TABLE="magebase-terraform-locks-management"

          # Check if resources exist
          if aws s3 ls "s3://$STATE_BUCKET" >/dev/null 2>&1 && aws dynamodb describe-table --table-name "$DYNAMODB_TABLE" >/dev/null 2>&1; then
            echo "‚úÖ Bootstrap resources already exist"
          else
            export TF_VAR_management_account_id="${{ vars.MANAGEMENT_ACCOUNT_ID }}"
            export AWS_REGION="${{ env.INFRA_REGION }}"
            terraform init -upgrade
            terraform apply -auto-approve -var-file=terraform.tfvars
          fi

          echo "state_bucket=$STATE_BUCKET" >> $GITHUB_OUTPUT
          echo "dynamodb_table=$DYNAMODB_TABLE" >> $GITHUB_OUTPUT
  base-infrastructure-deploy:
    name: "Base Infrastructure Deployment (k3s Cluster)"
    runs-on: ubicloud-standard-2-arm
    needs: [bootstrap]
    permissions:
      id-token: write
      contents: write
      pull-requests: write
    # Skip if we're not doing a full deployment (depends on bootstrap only)
    if: (needs.bootstrap.result == 'success') && (github.event_name != 'workflow_dispatch' || (github.event.inputs.action != 'plan' && github.event.inputs.action != 'destroy'))
    defaults:
      run:
        working-directory: infra/pipeline/base-infrastructure

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Calculate semantic version (dry run)
        id: calculate-version
        uses: cycjimmy/semantic-release-action@v4
        with:
          branches: main
          dry_run: true
          extra_plugins: |
            @semantic-release/git
            @semantic-release/github
            @semantic-release/changelog
            @semantic-release/exec
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: "1.23"

      - name: Get Infrastructure Account ID
        id: get-infra-account
        run: |
          # Use management account for base infrastructure (SSO is commented out)
          ACCOUNT_ID="${{ vars.MANAGEMENT_ACCOUNT_ID }}"
          echo "Using management account for base infrastructure: $ACCOUNT_ID"
          echo "account_id=$ACCOUNT_ID" >> $GITHUB_OUTPUT

      - name: Configure AWS credentials via OIDC
        id: oidc-auth
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ steps.get-infra-account.outputs.account_id }}:role/${{ vars.AWS_PIPELINE_ROLE }}
          aws-region: ${{ env.INFRA_REGION }}
        continue-on-error: true

      - name: Handle State Locks
        if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'plan') || (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
        run: |
          echo "üîç Checking for existing Terraform state locks..."

          # Wait for any existing locks to be released (with timeout)
          MAX_WAIT=300  # 5 minutes
          WAIT_COUNT=0

          while [ $WAIT_COUNT -lt $MAX_WAIT ]; do
            LOCK_ITEMS=$(aws dynamodb scan \
              --table-name "magebase-terraform-locks-management" \
              --region ${{ env.INFRA_REGION }} \
              --query 'Items[?attribute_exists(LockID)]' \
              --output json 2>/dev/null || echo "[]")

            LOCK_COUNT=$(echo "$LOCK_ITEMS" | jq length 2>/dev/null || echo "0")

            if [ "$LOCK_COUNT" -eq 0 ]; then
              echo "‚úÖ No state locks found - proceeding with Terraform operations"
              break
            else
              echo "üîí Found $LOCK_COUNT existing state lock(s), waiting..."
              for i in $(seq 0 $(($LOCK_COUNT - 1))); do
                LOCK_ID=$(echo "$LOCK_ITEMS" | jq -r ".[$i].LockID.S" 2>/dev/null || echo "")
                LOCK_INFO=$(echo "$LOCK_ITEMS" | jq -r ".[$i].Info.S" 2>/dev/null || echo "")
                if [ -n "$LOCK_ID" ]; then
                  echo "  Lock ID: $LOCK_ID"
                  echo "  Info: $LOCK_INFO"
                fi
              done

              WAIT_COUNT=$((WAIT_COUNT + 30))
              if [ $WAIT_COUNT -lt $MAX_WAIT ]; then
                echo "‚è≥ Waiting 30 seconds before checking again... ($WAIT_COUNT/$MAX_WAIT seconds)"
                sleep 30
              fi
            fi
          done

          if [ $WAIT_COUNT -ge $MAX_WAIT ]; then
            echo "‚ùå Timeout waiting for state locks to be released"
            echo "üîì Attempting to force unlock existing locks..."

            # Force unlock any remaining locks
            for i in $(seq 0 $(($LOCK_COUNT - 1))); do
              LOCK_ID=$(echo "$LOCK_ITEMS" | jq -r ".[$i].LockID.S" 2>/dev/null || echo "")
              if [ -n "$LOCK_ID" ]; then
                echo "üîì Force unlocking: $LOCK_ID"
                if terraform force-unlock -force "$LOCK_ID" 2>/dev/null; then
                  echo "‚úÖ Successfully force unlocked: $LOCK_ID"
                  break
                else
                  echo "‚ö†Ô∏è  Force unlock failed for: $LOCK_ID"
                fi
              fi
            done
          fi

          echo "üîÑ Proceeding with Terraform operations..."

      - name: Terraform Init
        id: init
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment || 'dev' }}"
          terraform init -upgrade \
            -backend-config="bucket=${{ needs.bootstrap.outputs.state_bucket }}" \
            -backend-config="key=magebase/base-infrastructure/${ENVIRONMENT}/terraform.tfstate"

      - name: Install ArgoCD CLI for bcrypt generation
        id: install-argocd
        run: |
          # Download and install ArgoCD CLI
          curl -sSL -o argocd-linux-arm64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-arm64
          sudo install -m 555 argocd-linux-arm64 /usr/local/bin/argocd
          rm argocd-linux-arm64
          argocd version --client

      - name: Generate ArgoCD bcrypt password
        id: bcrypt-password
        run: |
          # Generate bcrypt hash from the plain text password
          BCRYPT_HASH=$(argocd account bcrypt --password "${{ secrets.ARGOCD_ADMIN_PASSWORD }}")
          echo "::add-mask::$BCRYPT_HASH"
          echo "ARGOCD_BCRYPT_PASSWORD=$BCRYPT_HASH" >> $GITHUB_ENV

      - name: Terraform Validate
        id: validate
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
        run: |
          terraform validate

      - name: Terraform Format Check
        id: fmt
        working-directory: infra/pipeline/base-infrastructure
        run: |
          terraform fmt -check -recursive

      - name: Terraform Plan
        id: base-tf-plan
        if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'plan')
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
        run: |
          terraform plan -no-color -out=tfplan
        continue-on-error: true

      - name: Terraform Plan (Push to Main)
        id: base-tf-plan-main
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
          AWS_REGION: ${{ env.INFRA_REGION }}
        run: |
          echo "üöÄ Running Terraform plan for base infrastructure deployment..."

          # Retry logic for state lock conflicts
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "üìã Attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"

            if terraform plan -no-color -out=tfplan; then
              echo "‚úÖ Terraform plan completed successfully"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚ö†Ô∏è  Terraform plan failed, retrying in 30 seconds..."
                sleep 30
              else
                echo "‚ùå Terraform plan failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done

      - name: Update Pull Request
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request' && (steps.tf-plan.outcome == 'success' || steps.tf-plan-main.outcome == 'success')
        env:
          PLAN: "terraform\n${{ steps.tf-plan.outputs.stdout || steps.tf-plan-main.outputs.stdout }}"
        with:
          script: |
            const planOutcome = '${{ steps.tf-plan.outcome }}' === 'success' ? '${{ steps.tf-plan.outcome }}' : '${{ steps.tf-plan-main.outcome }}';
            const output = `#### Base Infrastructure Deployment üèóÔ∏è (k3s Cluster)
            #### Terraform Format and Validate üñå\`${{ steps.fmt.outcome }}\`
            #### Terraform Plan üìñ\`${planOutcome}\`

            <details><summary>Show Plan</summary>

            \`\`\`\n
            ${process.env.PLAN}
            \`\`\`

            </details>

            *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

      # - name: Run Base Infrastructure Terratest
      #   if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'plan')
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Base Infrastructure Terratest..."

      #     # Install dependencies
      #     go mod download

      #     # Run base infrastructure test
      #     go test -v -run TestBaseInfrastructure ./*.go

      #     echo "‚úÖ Base Infrastructure Terratest completed successfully"

      - name: Install kubectl
        if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
        uses: azure/setup-kubectl@v4
        with:
          version: "v1.30.0"

      - name: Kubectl Diff (Preview Kubernetes Changes)
        if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
          AWS_REGION: ${{ env.INFRA_REGION }}
        run: |
          echo "üîç Previewing Kubernetes changes with kubectl diff..."

          # Get kubeconfig from Terraform output
          echo "üì• Retrieving kubeconfig from Terraform..."
          terraform output -raw kubeconfig > kubeconfig.yaml

          # Set up kubectl with the retrieved kubeconfig
          export KUBECONFIG=./kubeconfig.yaml

          # Test kubectl connection
          echo "üîó Testing kubectl connection..."
          kubectl cluster-info --request-timeout=30s

          # Run kubectl diff to show what will change
          echo "üìã Running kubectl diff to preview changes..."

          # Handle template files by creating temporary copies without .tpl extension
          echo "üîß Processing template files..."
          find ./extra-manifests/ -name "*.yaml.tpl" -exec bash -c 'cp "$1" "${1%.tpl}"' _ {} \;

          # Create temporary kustomization file
          cp ./extra-manifests/kustomization.yaml.tpl ./extra-manifests/kustomization.yaml

          # Replace environment variables in all copied YAML files
          echo "üîß Substituting environment variables in all YAML files..."
          export ENVIRONMENT="${TF_VAR_environment}"
          export DOMAIN="magebase.dev"
          export ARGOCD_FQDN="${TF_VAR_environment}.argocd.magebase.dev"
          export ARGOCD_ADMIN_PASSWORD="$TF_VAR_argocd_admin_password"
          export ARGOCD_REPO_TOKEN="$TF_VAR_argocd_repo_token"
          export ENCRYPTION_KEY="$TF_VAR_encryption_key"
          export CLOUDFLARE_API_TOKEN="$TF_VAR_cloudflare_api_token"
          export AWS_ACCOUNT_ID="$TF_VAR_management_account_id"
          export AWS_REGION="$AWS_REGION"
          export R2_BUCKET="$TF_VAR_cloudflare_r2_bucket"
          export R2_ENDPOINT="$TF_VAR_cloudflare_r2_endpoint"
          export R2_ACCESS_KEY_ID="$TF_VAR_cloudflare_r2_access_key_id"
          export R2_SECRET_ACCESS_KEY="$TF_VAR_cloudflare_r2_secret_access_key"
          export SSH_PRIVATE_KEY="$TF_VAR_ssh_private_key"
          export SSH_PUBLIC_KEY="$TF_VAR_ssh_public_key"

          # Export ESO variables dynamically from clients.json
          CLIENTS_FILE="infra/pipeline/base-infrastructure/clients.json"
          if [ -f "$CLIENTS_FILE" ]; then
            CLIENT_COUNT=$(jq '. | length' "$CLIENTS_FILE")
            for i in $(seq 0 $(($CLIENT_COUNT - 1))); do
              CLIENT_NAME=$(jq -r ".[$i].name" "$CLIENTS_FILE")
              CLIENT_NAME_UPPER=$(echo "$CLIENT_NAME" | tr '[:lower:]' '[:upper:]')
              export ESO_${CLIENT_NAME_UPPER}_ACCESS_KEY_ID="$TF_VAR_eso_${CLIENT_NAME}_access_key_id"
              export ESO_${CLIENT_NAME_UPPER}_SECRET_ACCESS_KEY="$TF_VAR_eso_${CLIENT_NAME}_secret_access_key"
              export ESO_${CLIENT_NAME_UPPER}_POLICY_ARN="$TF_VAR_eso_${CLIENT_NAME}_policy_arn"

              # Export targetRevision variables for each environment
              export ${CLIENT_NAME_UPPER}_TARGET_REVISION_DEV=$(jq -r ".[$i].targetRevision.dev" "$CLIENTS_FILE")
              export ${CLIENT_NAME_UPPER}_TARGET_REVISION_QA=$(jq -r ".[$i].targetRevision.qa" "$CLIENTS_FILE")
              export ${CLIENT_NAME_UPPER}_TARGET_REVISION_UAT=$(jq -r ".[$i].targetRevision.uat" "$CLIENTS_FILE")
              export ${CLIENT_NAME_UPPER}_TARGET_REVISION_PROD=$(jq -r ".[$i].targetRevision.prod" "$CLIENTS_FILE")
            done
          else
            echo "‚ö†Ô∏è  clients.json not found, using legacy ESO variables"
            export ESO_GENFIX_ACCESS_KEY_ID="$TF_VAR_eso_genfix_access_key_id"
            export ESO_GENFIX_SECRET_ACCESS_KEY="$TF_VAR_eso_genfix_secret_access_key"
            export ESO_SITE_ACCESS_KEY_ID="$TF_VAR_eso_site_access_key_id"
            export ESO_SITE_SECRET_ACCESS_KEY="$TF_VAR_eso_site_secret_access_key"
            export ESO_GENFIX_POLICY_ARN="$TF_VAR_eso_genfix_policy_arn"
            export ESO_SITE_POLICY_ARN="$TF_VAR_eso_site_policy_arn"
          fi

          # Use sed for variable substitution (more reliable than envsubst)
          SED_COMMANDS=""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${ENVIRONMENT}|${ENVIRONMENT}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${DOMAIN}|${DOMAIN}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${ARGOCD_FQDN}|${ARGOCD_FQDN}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${ARGOCD_ADMIN_PASSWORD}|${ARGOCD_ADMIN_PASSWORD}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${ARGOCD_REPO_TOKEN}|${ARGOCD_REPO_TOKEN}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${ENCRYPTION_KEY}|${ENCRYPTION_KEY}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${CLOUDFLARE_API_TOKEN}|${CLOUDFLARE_API_TOKEN}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${AWS_ACCOUNT_ID}|${AWS_ACCOUNT_ID}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${AWS_REGION}|${AWS_REGION}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${R2_BUCKET}|${R2_BUCKET}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${R2_ENDPOINT}|${R2_ENDPOINT}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${R2_ACCESS_KEY_ID}|${R2_ACCESS_KEY_ID}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${R2_SECRET_ACCESS_KEY}|${R2_SECRET_ACCESS_KEY}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${SSH_PRIVATE_KEY}|${SSH_PRIVATE_KEY}|g\""
          SED_COMMANDS="$SED_COMMANDS -e \"s|\${SSH_PUBLIC_KEY}|${SSH_PUBLIC_KEY}|g\""

          # Add dynamic ESO variables from clients.json
          if [ -f "$CLIENTS_FILE" ]; then
            CLIENT_COUNT=$(jq '. | length' "$CLIENTS_FILE")
            for i in $(seq 0 $(($CLIENT_COUNT - 1))); do
              CLIENT_NAME=$(jq -r ".[$i].name" "$CLIENTS_FILE")
              CLIENT_NAME_UPPER=$(echo "$CLIENT_NAME" | tr '[:lower:]' '[:upper:]')
              ESO_ACCESS_KEY_VAR="ESO_${CLIENT_NAME_UPPER}_ACCESS_KEY_ID"
              ESO_SECRET_KEY_VAR="ESO_${CLIENT_NAME_UPPER}_SECRET_ACCESS_KEY"
              ESO_POLICY_ARN_VAR="ESO_${CLIENT_NAME_UPPER}_POLICY_ARN"
              SED_COMMANDS="$SED_COMMANDS -e \"s|\${${ESO_ACCESS_KEY_VAR}}|${!ESO_ACCESS_KEY_VAR}|g\""
              SED_COMMANDS="$SED_COMMANDS -e \"s|\${${ESO_SECRET_KEY_VAR}}|${!ESO_SECRET_KEY_VAR}|g\""
              SED_COMMANDS="$SED_COMMANDS -e \"s|\${${ESO_POLICY_ARN_VAR}}|${!ESO_POLICY_ARN_VAR}|g\""

              # Add targetRevision variables for sed replacement
              TARGET_REV_DEV_VAR="${CLIENT_NAME_UPPER}_TARGET_REVISION_DEV"
              TARGET_REV_QA_VAR="${CLIENT_NAME_UPPER}_TARGET_REVISION_QA"
              TARGET_REV_UAT_VAR="${CLIENT_NAME_UPPER}_TARGET_REVISION_UAT"
              TARGET_REV_PROD_VAR="${CLIENT_NAME_UPPER}_TARGET_REVISION_PROD"
              SED_COMMANDS="$SED_COMMANDS -e \"s|\${${TARGET_REV_DEV_VAR}}|${!TARGET_REV_DEV_VAR}|g\""
              SED_COMMANDS="$SED_COMMANDS -e \"s|\${${TARGET_REV_QA_VAR}}|${!TARGET_REV_QA_VAR}|g\""
              SED_COMMANDS="$SED_COMMANDS -e \"s|\${${TARGET_REV_UAT_VAR}}|${!TARGET_REV_UAT_VAR}|g\""
              SED_COMMANDS="$SED_COMMANDS -e \"s|\${${TARGET_REV_PROD_VAR}}|${!TARGET_REV_PROD_VAR}|g\""
            done
          else
            # Fallback to legacy ESO variables
            SED_COMMANDS="$SED_COMMANDS -e \"s|\${ESO_GENFIX_ACCESS_KEY_ID}|${ESO_GENFIX_ACCESS_KEY_ID}|g\""
            SED_COMMANDS="$SED_COMMANDS -e \"s|\${ESO_GENFIX_SECRET_ACCESS_KEY}|${ESO_GENFIX_SECRET_ACCESS_KEY}|g\""
            SED_COMMANDS="$SED_COMMANDS -e \"s|\${ESO_SITE_ACCESS_KEY_ID}|${ESO_SITE_ACCESS_KEY_ID}|g\""
            SED_COMMANDS="$SED_COMMANDS -e \"s|\${ESO_SITE_SECRET_ACCESS_KEY}|${ESO_SITE_SECRET_ACCESS_KEY}|g\""
            SED_COMMANDS="$SED_COMMANDS -e \"s|\${ESO_GENFIX_POLICY_ARN}|${ESO_GENFIX_POLICY_ARN}|g\""
            SED_COMMANDS="$SED_COMMANDS -e \"s|\${ESO_SITE_POLICY_ARN}|${ESO_SITE_POLICY_ARN}|g\""
          fi

          find ./extra-manifests/ -name "*.yaml" -exec sed -i $SED_COMMANDS {} \;

          # Run kubectl diff using kustomize
          echo "üîç Running kubectl diff with detailed output..."
          set +e  # Don't exit on diff command failure
          kubectl diff -k ./extra-manifests/ --server-side --force-conflicts 2>&1 | head -100
          DIFF_EXIT_CODE=$?
          set -e  # Re-enable exit on error

          if [ $DIFF_EXIT_CODE -eq 0 ]; then
            echo "‚úÖ No differences found - manifests are up to date"
          elif [ $DIFF_EXIT_CODE -eq 1 ]; then
            echo "üìã Differences found - manifests will be updated during apply"
          else
            echo "‚ö†Ô∏è  kubectl diff encountered issues (exit code: $DIFF_EXIT_CODE)"
          fi

          # Clean up temporary files
          find ./extra-manifests/ -name "*.yaml" -exec bash -c 'if [ -f "${1%.yaml}.yaml.tpl" ]; then rm "$1"; fi' _ {} \;
          rm -f ./extra-manifests/kustomization.yaml

          # Clean up kubeconfig file
          rm -f kubeconfig.yaml

      - name: Terraform Apply (Push to Main)
        id: base-tf-apply-main
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
          AWS_REGION: ${{ env.INFRA_REGION }}
        run: |
          echo "üöÄ Applying base infrastructure changes..."

          # Apply with retry logic
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "üìã Apply attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"

            if terraform apply -auto-approve tfplan; then
              echo "‚úÖ Terraform apply completed successfully"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚ö†Ô∏è  Terraform apply failed, retrying in 30 seconds..."
                sleep 30
              else
                echo "‚ùå Terraform apply failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done

      - name: Generate Terraform Outputs
        if: steps.base-tf-apply-main.outcome == 'success' && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
        run: |
          echo "üìä Generating Terraform outputs for sharing..."
          terraform output -json > terraform-outputs.json
          echo "‚úÖ Outputs generated: terraform-outputs.json"

      - name: Create GitHub Release
        if: steps.base-tf-apply-main.outcome == 'success' && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
        uses: softprops/action-gh-release@v2
        with:
          tag_name: base-outputs-${{ github.run_id }}
          name: Base Infrastructure Outputs ${{ github.run_id }}
          body: |
            Latest Terraform outputs from base infrastructure deployment.

            **Environment:** ${{ github.event.inputs.environment || 'dev' }}
            **Generated:** ${{ github.event.head_commit.timestamp }}
            **Commit:** ${{ github.sha }}
            **Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

            This release contains the terraform-outputs.json file with all infrastructure outputs that can be consumed by dependent repositories.
          files: terraform-outputs.json
          draft: false
          prerelease: false
          generate_release_notes: true

      - name: Display Release Information
        if: steps.base-tf-apply-main.outcome == 'success' && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
        run: |
          echo "## üì¶ Infrastructure Outputs Published" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ **Release Created:** base-outputs-${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "üìä **Outputs File:** terraform-outputs.json" >> $GITHUB_STEP_SUMMARY
          echo "üîó **Download URL:** ${{ github.server_url }}/${{ github.repository }}/releases/download/base-outputs-${{ github.run_id }}/terraform-outputs.json" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìã Dependent Repositories:" >> $GITHUB_STEP_SUMMARY
          echo "- Download the terraform-outputs.json from this release" >> $GITHUB_STEP_SUMMARY
          echo "- Parse the JSON to extract required values" >> $GITHUB_STEP_SUMMARY
          echo "- Use outputs in your Terraform configurations" >> $GITHUB_STEP_SUMMARY

      # - name: Run Base Infrastructure Terratest
      #   if: success() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Base Infrastructure Terratest after apply..."

      #     # Install dependencies
      #     go mod download

      #     # Run base infrastructure test
      #     go test -v -run TestBaseInfrastructure ./*.go -timeout 30m

      #     echo "‚úÖ Base Infrastructure Terratest completed successfully"

      # - name: Run Integration Terratest
      #   if: success() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     AWS_SSO_START_URL: ${{ secrets.AWS_SSO_START_URL }}
      #     AWS_SSO_REGION: ${{ env.SSO_REGION }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Integration Terratest after apply..."

      #     # Install dependencies
      #     go mod download

      #     # Run integration test
      #     go test -v -run TestIntegration ./*.go -timeout 45m

      #     echo "‚úÖ Integration Terratest completed successfully"

      # - name: Run Unified Terratest
      #   if: success() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     AWS_SSO_START_URL: ${{ secrets.AWS_SSO_START_URL }}
      #     AWS_SSO_REGION: ${{ env.SSO_REGION }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Unified Terratest after apply..."

      #     # Install dependencies
      #     go mod download

      #     # Run unified test (include all test files)
      #     go test -v -run TestUnifiedInfrastructure ./*.go -timeout 45m

      #     echo "‚úÖ Unified Terratest completed successfully"

      - name: Force Unlock Base Infrastructure on Failure
        if: failure() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
        run: |
          echo "üîç Attempting to force unlock base infrastructure Terraform state after failure..."

          # Try to scan DynamoDB for any existing locks
          echo "üîç Scanning DynamoDB for existing base infrastructure locks..."
          LOCK_ITEMS=$(aws dynamodb scan \
            --table-name "magebase-terraform-locks-management" \
            --region ${{ env.INFRA_REGION }} \
            --query 'Items[?attribute_exists(LockID)]' \
            --output json 2>/dev/null || echo "[]")

          LOCK_COUNT=$(echo "$LOCK_ITEMS" | jq length 2>/dev/null || echo "0")

          if [ "$LOCK_COUNT" -gt 0 ]; then
            echo "üîí Found $LOCK_COUNT existing base infrastructure state lock(s), attempting to force unlock..."

            # Process each lock item
            for i in $(seq 0 $(($LOCK_COUNT - 1))); do
              LOCK_ID=$(echo "$LOCK_ITEMS" | jq -r ".[$i].LockID.S" 2>/dev/null || echo "")
              LOCK_INFO=$(echo "$LOCK_ITEMS" | jq -r ".[$i].Info.S" 2>/dev/null || echo "")

              if [ -n "$LOCK_ID" ]; then
                echo "üîì Attempting to force unlock base infrastructure: $LOCK_ID"
                echo "Lock info: $LOCK_INFO"

                # Attempt force unlock
                if terraform force-unlock -force "$LOCK_ID" 2>/dev/null; then
                  echo "‚úÖ Successfully force unlocked base infrastructure: $LOCK_ID"
                  break
                else
                  echo "‚ö†Ô∏è  Force unlock failed for base infrastructure: $LOCK_ID"
                fi
              fi
            done
          else
            echo "‚ÑπÔ∏è  No base infrastructure locks found in DynamoDB table"
          fi

          # Provide manual instructions
          echo ""
          echo "üìã If the automatic unlock failed, please manually force-unlock the base infrastructure state:"
          echo "1. Find the lock ID from the failed base infrastructure deployment step logs above"
          echo "2. Run: cd infra/pipeline/base-infrastructure && terraform force-unlock -force <lock_id>"
          echo "3. Re-run the workflow"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.INFRA_REGION }}

      # - name: Run Integration Terratest
      #   if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     AWS_SSO_START_URL: ${{ secrets.AWS_SSO_START_URL }}
      #     AWS_SSO_REGION: ${{ env.SSO_REGION }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Integration Terratest..."

      #     # Install dependencies
      #     go mod download

      #     # Run integration test
      #     go test -v -run TestIntegration ./*.go

      #     echo "‚úÖ Integration Terratest completed successfully"

      # - name: Run Unified Terratest
      #   if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     AWS_SSO_START_URL: ${{ secrets.AWS_SSO_START_URL }}
      #     AWS_SSO_REGION: ${{ env.SSO_REGION }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Unified Terratest..."

      #     # Install dependencies
      #     go mod download

      #     # Run unified test (include all test files)
      #     go test -v -run TestUnifiedInfrastructure ./*.go

      #     echo "‚úÖ Unified Terratest completed successfully"

      - name: Terraform Destroy
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'destroy'
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
          AWS_REGION: ${{ env.INFRA_REGION }}
        run: |
          terraform destroy -auto-approve

  base-infrastructure-destroy:
    name: "Base Infrastructure Destroy (k3s Cluster)"
    runs-on: ubicloud-standard-2-arm
    needs: [bootstrap]
    permissions:
      id-token: write
      contents: write
      pull-requests: write
    # Only run on manual trigger with destroy action
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'destroy'
    defaults:
      run:
        working-directory: infra/pipeline/base-infrastructure

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: "1.23"

      - name: Get Infrastructure Account ID
        id: get-infra-account
        run: |
          # Use management account for base infrastructure (SSO is commented out)
          ACCOUNT_ID="${{ vars.MANAGEMENT_ACCOUNT_ID }}"
          echo "Using management account for base infrastructure: $ACCOUNT_ID"
          echo "account_id=$ACCOUNT_ID" >> $GITHUB_OUTPUT

      - name: Configure AWS credentials via OIDC
        id: oidc-auth
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ steps.get-infra-account.outputs.account_id }}:role/${{ vars.AWS_PIPELINE_ROLE }}
          aws-region: ${{ env.INFRA_REGION }}
        continue-on-error: true

      - name: Handle State Locks
        if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'plan') || (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
        run: |
          echo "üîç Checking for existing Terraform state locks..."

          # Wait for any existing locks to be released (with timeout)
          MAX_WAIT=300  # 5 minutes
          WAIT_COUNT=0

          while [ $WAIT_COUNT -lt $MAX_WAIT ]; do
            LOCK_ITEMS=$(aws dynamodb scan \
              --table-name "magebase-terraform-locks-management" \
              --region ${{ env.INFRA_REGION }} \
              --query 'Items[?attribute_exists(LockID)]' \
              --output json 2>/dev/null || echo "[]")

            LOCK_COUNT=$(echo "$LOCK_ITEMS" | jq length 2>/dev/null || echo "0")

            if [ "$LOCK_COUNT" -eq 0 ]; then
              echo "‚úÖ No state locks found - proceeding with Terraform operations"
              break
            else
              echo "üîí Found $LOCK_COUNT existing state lock(s), waiting..."
              for i in $(seq 0 $(($LOCK_COUNT - 1))); do
                LOCK_ID=$(echo "$LOCK_ITEMS" | jq -r ".[$i].LockID.S" 2>/dev/null || echo "")
                LOCK_INFO=$(echo "$LOCK_ITEMS" | jq -r ".[$i].Info.S" 2>/dev/null || echo "")
                if [ -n "$LOCK_ID" ]; then
                  echo "  Lock ID: $LOCK_ID"
                  echo "  Info: $LOCK_INFO"
                fi
              done

              WAIT_COUNT=$((WAIT_COUNT + 30))
              if [ $WAIT_COUNT -lt $MAX_WAIT ]; then
                echo "‚è≥ Waiting 30 seconds before checking again... ($WAIT_COUNT/$MAX_WAIT seconds)"
                sleep 30
              fi
            fi
          done

          if [ $WAIT_COUNT -ge $MAX_WAIT ]; then
            echo "‚ùå Timeout waiting for state locks to be released"
            echo "üîì Attempting to force unlock existing locks..."

            # Force unlock any remaining locks
            for i in $(seq 0 $(($LOCK_COUNT - 1))); do
              LOCK_ID=$(echo "$LOCK_ITEMS" | jq -r ".[$i].LockID.S" 2>/dev/null || echo "")
              if [ -n "$LOCK_ID" ]; then
                echo "üîì Force unlocking: $LOCK_ID"
                if terraform force-unlock -force "$LOCK_ID" 2>/dev/null; then
                  echo "‚úÖ Successfully force unlocked: $LOCK_ID"
                  break
                else
                  echo "‚ö†Ô∏è  Force unlock failed for: $LOCK_ID"
                fi
              fi
            done
          fi

          echo "üîÑ Proceeding with Terraform operations..."

      - name: Terraform Init
        id: init
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment || 'dev' }}"
          terraform init -upgrade \
            -backend-config="bucket=${{ needs.bootstrap.outputs.state_bucket }}" \
            -backend-config="key=magebase/base-infrastructure/${ENVIRONMENT}/terraform.tfstate"

      - name: Install ArgoCD CLI for bcrypt generation
        id: install-argocd
        run: |
          # Download and install ArgoCD CLI
          curl -sSL -o argocd-linux-arm64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-arm64
          sudo install -m 555 argocd-linux-arm64 /usr/local/bin/argocd
          rm argocd-linux-arm64
          argocd version --client

      - name: Generate ArgoCD bcrypt password
        id: bcrypt-password
        run: |
          # Generate bcrypt hash from the plain text password
          BCRYPT_HASH=$(argocd account bcrypt --password "${{ secrets.ARGOCD_ADMIN_PASSWORD }}")
          echo "::add-mask::$BCRYPT_HASH"
          echo "ARGOCD_BCRYPT_PASSWORD=$BCRYPT_HASH" >> $GITHUB_ENV

      - name: Terraform Validate
        id: validate
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
        run: |
          terraform validate

      - name: Terraform Format Check
        id: fmt
        working-directory: infra/pipeline/base-infrastructure
        run: |
          terraform fmt -check -recursive

      - name: Terraform Plan
        id: base-tf-plan
        if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'plan')
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
        run: |
          terraform plan -no-color -out=tfplan
        continue-on-error: true

      - name: Terraform Plan (Push to Main)
        id: base-tf-plan-main
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
        run: |
          echo "üöÄ Running Terraform plan for base infrastructure deployment..."

          # Retry logic for state lock conflicts
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "üìã Attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"

            if terraform plan -no-color -out=tfplan; then
              echo "‚úÖ Terraform plan completed successfully"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚ö†Ô∏è  Terraform plan failed, retrying in 30 seconds..."
                sleep 30
              else
                echo "‚ùå Terraform plan failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done

      - name: Update Pull Request
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request' && (steps.tf-plan.outcome == 'success' || steps.tf-plan-main.outcome == 'success')
        env:
          PLAN: "terraform\n${{ steps.tf-plan.outputs.stdout || steps.tf-plan-main.outputs.stdout }}"
        with:
          script: |
            const planOutcome = '${{ steps.tf-plan.outcome }}' === 'success' ? '${{ steps.tf-plan.outcome }}' : '${{ steps.tf-plan-main.outcome }}';
            const output = `#### Base Infrastructure Deployment üèóÔ∏è (k3s Cluster)
            #### Terraform Format and Validate üñå\`${{ steps.fmt.outcome }}\`
            #### Terraform Plan üìñ\`${planOutcome}\`

            <details><summary>Show Plan</summary>

            \`\`\`\n
            ${process.env.PLAN}
            \`\`\`

            </details>

            *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

      # - name: Run Base Infrastructure Terratest
      #   if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'plan')
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Base Infrastructure Terratest..."

      #     # Install dependencies
      #     go mod download

      #     # Run base infrastructure test
      #     go test -v -run TestBaseInfrastructure ./*.go

      #     echo "‚úÖ Base Infrastructure Terratest completed successfully"

      - name: Terraform Destroy
        id: base-tf-destroy-main
        working-directory: infra/pipeline/base-infrastructure
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_management_account_id: ${{ vars.MANAGEMENT_ACCOUNT_ID }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
        run: |
          echo "üöÄ Applying base infrastructure changes..."

          # Apply with retry logic
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "üìã Apply attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"

            if terraform destroy -auto-approve; then
              echo "‚úÖ Terraform destroy completed successfully"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚ö†Ô∏è  Terraform destroy failed, retrying in 30 seconds..."
                sleep 30
              else
                echo "‚ùå Terraform destroy failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done

      - name: Generate Terraform Outputs
        if: success() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
        run: |
          echo "üìä Generating Terraform outputs for sharing..."
          terraform output -json > terraform-outputs.json
          echo "‚úÖ Outputs generated: terraform-outputs.json"

      - name: Display Release Information
        if: success() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
        run: |
          echo "## üì¶ Infrastructure Outputs Published" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ **Release Created:** base-outputs-${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "üìä **Outputs File:** terraform-outputs.json" >> $GITHUB_STEP_SUMMARY
          echo "üîó **Download URL:** ${{ github.server_url }}/${{ github.repository }}/releases/download/base-outputs-${{ github.run_id }}/terraform-outputs.json" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìã Dependent Repositories:" >> $GITHUB_STEP_SUMMARY
          echo "- Download the terraform-outputs.json from this release" >> $GITHUB_STEP_SUMMARY
          echo "- Parse the JSON to extract required values" >> $GITHUB_STEP_SUMMARY
          echo "- Use outputs in your Terraform configurations" >> $GITHUB_STEP_SUMMARY

      # - name: Run Base Infrastructure Terratest
      #   if: success() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Base Infrastructure Terratest after apply..."

      #     # Install dependencies
      #     go mod download

      #     # Run base infrastructure test
      #     go test -v -run TestBaseInfrastructure ./*.go -timeout 30m

      #     echo "‚úÖ Base Infrastructure Terratest completed successfully"

      # - name: Run Integration Terratest
      #   if: success() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     AWS_SSO_START_URL: ${{ secrets.AWS_SSO_START_URL }}
      #     AWS_SSO_REGION: ${{ env.SSO_REGION }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Integration Terratest after apply..."

      #     # Install dependencies
      #     go mod download

      #     # Run integration test
      #     go test -v -run TestIntegration ./*.go -timeout 45m

      #     echo "‚úÖ Integration Terratest completed successfully"

      # - name: Run Unified Terratest
      #   if: success() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     AWS_SSO_START_URL: ${{ secrets.AWS_SSO_START_URL }}
      #     AWS_SSO_REGION: ${{ env.SSO_REGION }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Unified Terratest after apply..."

      #     # Install dependencies
      #     go mod download

      #     # Run unified test (include all test files)
      #     go test -v -run TestUnifiedInfrastructure ./*.go -timeout 45m

      #     echo "‚úÖ Unified Terratest completed successfully"

      - name: Force Unlock Base Infrastructure on Failure
        if: failure() && ((github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'))
        run: |
          echo "üîç Attempting to force unlock base infrastructure Terraform state after failure..."

          # Try to scan DynamoDB for any existing locks
          echo "üîç Scanning DynamoDB for existing base infrastructure locks..."
          LOCK_ITEMS=$(aws dynamodb scan \
            --table-name "magebase-terraform-locks-management" \
            --region ${{ env.INFRA_REGION }} \
            --query 'Items[?attribute_exists(LockID)]' \
            --output json 2>/dev/null || echo "[]")

          LOCK_COUNT=$(echo "$LOCK_ITEMS" | jq length 2>/dev/null || echo "0")

          if [ "$LOCK_COUNT" -gt 0 ]; then
            echo "üîí Found $LOCK_COUNT existing base infrastructure state lock(s), attempting to force unlock..."

            # Process each lock item
            for i in $(seq 0 $(($LOCK_COUNT - 1))); do
              LOCK_ID=$(echo "$LOCK_ITEMS" | jq -r ".[$i].LockID.S" 2>/dev/null || echo "")
              LOCK_INFO=$(echo "$LOCK_ITEMS" | jq -r ".[$i].Info.S" 2>/dev/null || echo "")

              if [ -n "$LOCK_ID" ]; then
                echo "üîì Attempting to force unlock base infrastructure: $LOCK_ID"
                echo "Lock info: $LOCK_INFO"

                # Attempt force unlock
                if terraform force-unlock -force "$LOCK_ID" 2>/dev/null; then
                  echo "‚úÖ Successfully force unlocked base infrastructure: $LOCK_ID"
                  break
                else
                  echo "‚ö†Ô∏è  Force unlock failed for base infrastructure: $LOCK_ID"
                fi
              fi
            done
          else
            echo "‚ÑπÔ∏è  No base infrastructure locks found in DynamoDB table"
          fi

          # Provide manual instructions
          echo ""
          echo "üìã If the automatic unlock failed, please manually force-unlock the base infrastructure state:"
          echo "1. Find the lock ID from the failed base infrastructure deployment step logs above"
          echo "2. Run: cd infra/pipeline/base-infrastructure && terraform force-unlock -force <lock_id>"
          echo "3. Re-run the workflow"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.INFRA_REGION }}

      # - name: Run Integration Terratest
      #   if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     AWS_SSO_START_URL: ${{ secrets.AWS_SSO_START_URL }}
      #     AWS_SSO_REGION: ${{ env.SSO_REGION }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Integration Terratest..."

      #     # Install dependencies
      #     go mod download

      #     # Run integration test
      #     go test -v -run TestIntegration ./*.go

      #     echo "‚úÖ Integration Terratest completed successfully"

      # - name: Run Unified Terratest
      #   if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply')
      #   working-directory: infra/tests
      #   env:
      #     AWS_REGION: ${{ env.INFRA_REGION }}
      #     TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
      #     TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
      #     TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
      #     AWS_SSO_START_URL: ${{ secrets.AWS_SSO_START_URL }}
      #     AWS_SSO_REGION: ${{ env.SSO_REGION }}
      #     TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
      #   run: |
      #     echo "üß™ Running Unified Terratest..."

      #     # Install dependencies
      #     go mod download

      #     # Run unified test (include all test files)
      #     go test -v -run TestUnifiedInfrastructure ./*.go

      #     echo "‚úÖ Unified Terratest completed successfully"

      - name: Terraform Destroy
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'destroy'
        env:
          TF_VAR_environment: ${{ github.event.inputs.environment || 'dev' }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_cloudflare_account_id: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          TF_VAR_cloudflare_zone_id: ${{ secrets.CLOUDFLARE_ZONE_ID }}
          TF_VAR_cloudflare_r2_access_key_id: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_ACCESS_KEY }}
          TF_VAR_cloudflare_r2_secret_access_key: ${{ secrets.CLOUDFLARE_OBJECT_STORAGE_SECRET_KEY }}
          TF_VAR_argocd_admin_password: ${{ env.ARGOCD_BCRYPT_PASSWORD }}
          TF_VAR_argocd_repo_token: ${{ secrets.ARGOCD_REPO_TOKEN }}
        run: |
          terraform destroy -auto-approve

  security-scan:
    name: Security and Compliance Scan
    runs-on: ubicloud-standard-2-arm
    needs: base-infrastructure-deploy
    permissions:
      contents: read
      security-events: write
      actions: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: "config"
          scan-ref: "./infra"
          format: "sarif"
          output: "trivy-results.sarif"

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        if: always() && env.ADVANCED_SECURITY_ENABLED == 'true'
        with:
          sarif_file: "trivy-results.sarif"
        continue-on-error: true

      - name: Check Advanced Security availability
        if: always()
        run: |
          echo "üîç Checking GitHub Advanced Security status..."
          if [ "${{ github.event.repository.private }}" == "true" ] || [ "${{ github.event.repository.visibility }}" == "private" ]; then
            echo "‚úÖ Private repository - Advanced Security should be available"
            echo "ADVANCED_SECURITY_ENABLED=true" >> $GITHUB_ENV
          else
            echo "‚ÑπÔ∏è  Public repository - Advanced Security may not be available for free tier"
            echo "ADVANCED_SECURITY_ENABLED=false" >> $GITHUB_ENV
          fi

      - name: Display scan results summary
        if: always()
        run: |
          echo "## üîí Security Scan Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "trivy-results.sarif" ]; then
            echo "‚úÖ Trivy scan completed successfully" >> $GITHUB_STEP_SUMMARY
            echo "- SARIF file generated: trivy-results.sarif" >> $GITHUB_STEP_SUMMARY

            if [ "${{ env.ADVANCED_SECURITY_ENABLED }}" == "true" ]; then
              echo "- Results uploaded to GitHub Security tab" >> $GITHUB_STEP_SUMMARY
            else
              echo "- ‚ö†Ô∏è  GitHub Advanced Security not available for SARIF upload" >> $GITHUB_STEP_SUMMARY
              echo "- üìÑ SARIF file available for manual review" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ùå Trivy scan failed - no results file generated" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìã Next Steps:" >> $GITHUB_STEP_SUMMARY
          echo "- Enable GitHub Advanced Security for automatic vulnerability tracking" >> $GITHUB_STEP_SUMMARY
          echo "- Review trivy-results.sarif for detailed findings" >> $GITHUB_STEP_SUMMARY
          echo "- Consider running additional security scans as needed" >> $GITHUB_STEP_SUMMARY

  # ===== SEMANTIC RELEASE =====
  semantic-release:
    name: "Semantic Release"
    runs-on: ubicloud-standard-2-arm
    needs: security-scan
    permissions:
      contents: write
      pull-requests: write
    outputs:
      new_release_published: ${{ steps.semantic.outputs.new_release_published }}
      new_release_version: ${{ steps.semantic.outputs.new_release_version }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Run semantic-release
        id: semantic
        uses: cycjimmy/semantic-release-action@v4
        with:
          branches: main
          dry_run: ${{ github.event_name == 'pull_request' }}
          extra_plugins: |
            @semantic-release/git
            @semantic-release/github
            @semantic-release/changelog
            @semantic-release/exec
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Publish package with Docker image link
        if: steps.semantic.outputs.new_release_published == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üì¶ Publishing package with Docker image links..."

          # Get the release version from semantic release output
          RELEASE_VERSION="${{ steps.semantic.outputs.new_release_version }}"

          echo "üöÄ New release published: ${RELEASE_VERSION}"

          # Read clients configuration
          CLIENTS_FILE="infra/pipeline/base-infrastructure/clients.json"
          if [ ! -f "$CLIENTS_FILE" ]; then
            echo "‚ùå clients.json file not found at $CLIENTS_FILE"
            exit 1
          fi

          # Query targetRevision from clients.json for Docker image links
          echo "üîç Getting targetRevision from client applications..."

          # Initialize variables
          RELEASE_NOTES="**Docker Images:**\n\n"
          DOCKER_IMAGES_LOG="üê≥ Docker Images:"

          # Read clients from JSON and process each one using jq
          CLIENT_COUNT=$(jq '. | length' "$CLIENTS_FILE")

          for i in $(seq 0 $(($CLIENT_COUNT - 1))); do
            REPO=$(jq -r ".[$i].repository" "$CLIENTS_FILE")
            CLIENT_NAME=$(jq -r ".[$i].name" "$CLIENTS_FILE")

            echo "üì¶ Processing client: $CLIENT_NAME (repo: $REPO)"

            # Get targetRevision for current environment from clients.json
            CURRENT_ENV="${TF_VAR_environment:-dev}"
            CLIENT_TARGET_REV=$(jq -r ".[$i].targetRevision.\"$CURRENT_ENV\" // \"main\"" "$CLIENTS_FILE")

            echo "‚úÖ Using targetRevision for $CURRENT_ENV: $CLIENT_TARGET_REV"

            CLIENT_IMAGE="ghcr.io/$REPO:$CLIENT_TARGET_REV"

            # Add to log output
            DOCKER_IMAGES_LOG="$DOCKER_IMAGES_LOG\n  - $CLIENT_NAME: $CLIENT_IMAGE"

            # Add to release notes
            RELEASE_NOTES+="**$CLIENT_NAME Application:** \`$CLIENT_IMAGE\`\n"
            RELEASE_NOTES+="[View on GHCR](https://github.com/$REPO/pkgs/container/$CLIENT_NAME)\n\n"
          done

          # Display the collected information
          echo -e "$DOCKER_IMAGES_LOG"

          # Add extensible section for future repositories
          RELEASE_NOTES+="---\n\n"
          RELEASE_NOTES+="*This release includes infrastructure updates that support the above application versions.*"

          # Update release notes with retry mechanism
          echo "üìù Updating release notes for ${RELEASE_VERSION}..."

          # Initial delay to allow GitHub to process the release
          echo "‚è≥ Waiting 3 seconds for GitHub to process the release..."
          sleep 3

          # Retry logic to handle GitHub API delays
          MAX_RETRIES=5
          RETRY_COUNT=0
          RETRY_DELAY=5

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "üîÑ Attempting to update release notes (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)..."

            if gh release edit ${RELEASE_VERSION} \
                --notes "${RELEASE_NOTES}" \
                --repo ${{ github.repository }}; then
              echo "‚úÖ Successfully updated release notes for ${RELEASE_VERSION}"
              break
            else
              echo "‚ùå Failed to update release notes for ${RELEASE_VERSION} (attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)"

              if [ $RETRY_COUNT -lt $((MAX_RETRIES - 1)) ]; then
                echo "‚è≥ Waiting ${RETRY_DELAY} seconds before retry..."
                sleep $RETRY_DELAY
                RETRY_DELAY=$((RETRY_DELAY * 2))  # Exponential backoff
              else
                echo "üîç Checking release status..."
                if gh release view ${RELEASE_VERSION} --repo ${{ github.repository }} 2>/dev/null; then
                  echo "Release ${RELEASE_VERSION} exists but update failed"
                else
                  echo "Release ${RELEASE_VERSION} not found"
                fi
                exit 1
              fi
            fi

            RETRY_COUNT=$((RETRY_COUNT + 1))
          done

          echo "‚úÖ Package published with Docker image links"

      - name: Set outputs for dry run
        if: github.event_name == 'pull_request'
        run: |
          echo "new_release_published=false" >> $GITHUB_OUTPUT
          echo "new_release_version=dry-run" >> $GITHUB_OUTPUT

  # ===== NOTIFICATION =====
  notify:
    name: "Pipeline Notification"
    runs-on: ubicloud-standard-2-arm
    needs:
      [bootstrap, base-infrastructure-deploy, security-scan, semantic-release]
    if: always()
    steps:
      - name: Success
        if: needs.base-infrastructure-deploy.result == 'success'
        run: echo "‚úÖ Deployment completed successfully"

      - name: Failure
        if: needs.base-infrastructure-deploy.result == 'failure'
        run: |
          echo "‚ùå Deployment failed"
          exit 1
